{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97a355c1",
   "metadata": {
    "id": "97a355c1"
   },
   "source": [
    "<center><h1>Grad Project #3</h1></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2946f4ee-7fdf-47c6-991d-079b0c2df9fc",
   "metadata": {},
   "source": [
    "In this final project for 16.413 / 6.4132, we are going to look at the search and rescue domain using symbolic representations. We are going to look at both planning using PDDL, and also inference using PDDL. This project isn't going to focus on implementing specific algorithms however -- we're going to use two libraries: `pyperplan` and `sympy`. (You'll remember `sympy` from problem set 8). \n",
    "\n",
    "The project is structured as follows: \n",
    "* [0. Credit for Contributors]\n",
    "* [1. Planning in Search and Rescue](!start)\n",
    "    * 1.1 Search and Rescue Warmup 1\n",
    "    * 1.2 Search and Rescue Warmup 2\n",
    "    * 1.3 Search and Rescue PDDL Planner\n",
    "* [2. Inference from observations](!inference)\n",
    "    * 2.1 Inferring unknown values\n",
    "    * 2.2 Belief update\n",
    "* [3. Putting It Together](!integrated)\n",
    "    * 3.1 Safe but not so smart\n",
    "    * 3.2 Safe and smart\n",
    "    * 3.3 Reckless\n",
    "* [4. Analysis](!analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b6fc67-c474-4e25-9382-a8769d43877e",
   "metadata": {},
   "source": [
    "## <a id=\"contributors\">0. Credit for Contributors</a>\n",
    "\n",
    "List the various students, lecture notes, or online resouces that helped you complete this project:\n",
    "\n",
    "Ex: I worked with Bob on the inference.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "Write your answer in the cell below this one.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba91c4f-9bc2-4e07-8ecd-a6d526cc5c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "--> *(double click on this cell to delete this text and type your answer here)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "254f9679",
   "metadata": {
    "id": "254f9679"
   },
   "source": [
    "## Imports and Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73755e0d",
   "metadata": {
    "collapsed": true,
    "id": "73755e0d",
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "!pip install pyperplan\n",
    "!pip install sympy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a05fd16",
   "metadata": {
    "collapsed": true,
    "id": "2a05fd16",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import copy\n",
    "import numpy as np\n",
    "import pdb\n",
    "from sympy import Symbol, And, Or, satisfiable\n",
    "from pyperplan.pddl.parser import Parser\n",
    "from pyperplan import grounding, planner\n",
    "import tempfile\n",
    "\n",
    "\n",
    "class State:\n",
    "    \"\"\"States have the following attributes:\n",
    "\n",
    "    \"robot\": A (row, col) representing the robot's loc.\n",
    "    \"hospital\": A (row, col) representing the hospital's loc.\n",
    "    \"carrying\": The str name of a person being carried,\n",
    "      or None, if no person is being carried.\n",
    "    \"people\": A dict mapping str people names to (row, col)\n",
    "      locs. If a person is being carried, they do not\n",
    "      appear in this dict.\n",
    "    \"state_map\": A numpy array of str 'C', 'F', 'S', and 'W',\n",
    "      where 'C' represents free space, 'F' represents fire,\n",
    "      'S' represents smoke, and 'W' represents an obstacle(wall).\n",
    "      The robot may safely enter any cell that is clear (‘C’)\n",
    "      or contains smoke (‘S’).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 robot=None,\n",
    "                 hospital=None,\n",
    "                 carrying=None,\n",
    "                 people=None,\n",
    "                 state_map=None):\n",
    "        default_state_map = np.array([['C', 'C', 'C', 'C', 'C', 'C', 'C'],\n",
    "                                      ['C', 'W', 'W', 'C', 'C', 'W', 'W'],\n",
    "                                      ['C', 'C', 'C', 'C', 'C', 'C', 'C'],\n",
    "                                      ['C', 'C', 'W', 'C', 'C', 'C', 'C'],\n",
    "                                      ['C', 'C', 'W', 'C', 'W', 'C', 'C'],\n",
    "                                      ['C', 'C', 'C', 'C', 'C', 'W', 'C'],\n",
    "                                      ['C', 'W', 'C', 'C', 'W', 'C', 'C']],\n",
    "                                     dtype=str)\n",
    "        default_robot = (0, 0)  # top left corner\n",
    "        default_hospital = (6, 6)  # bottom right corner\n",
    "        default_carrying = None\n",
    "        default_people = {\n",
    "            \"p1\": (4, 0),\n",
    "            \"p2\": (6, 0),\n",
    "            \"p3\": (0, 6),\n",
    "            \"p4\": (3, 3)\n",
    "        }\n",
    "        self.state_map = state_map if state_map is not None else default_state_map\n",
    "        self.robot = robot if robot is not None else default_robot\n",
    "        self.hospital = hospital if hospital is not None else default_hospital\n",
    "        self.carrying = carrying if carrying is not None else default_carrying\n",
    "        self.people = people if people is not None else default_people\n",
    "\n",
    "    def get_safe_grid(self):\n",
    "        \"\"\"\n",
    "        \"safe_grid\": A grid map of boolean values where `True`\n",
    "        indicate the locations where the robot are allowed to move into.\n",
    "\n",
    "        Clear and Smoke grid cells are safe to enter\n",
    "        \"\"\"\n",
    "        safe_grid = np.logical_or(self.state_map == \"C\", self.state_map == \"S\")\n",
    "        return safe_grid\n",
    "\n",
    "    def render(self, msg=None):\n",
    "        height, width = self.state_map.shape\n",
    "        state_arr = np.full((height, width), \"  \", dtype=object)\n",
    "        state_arr[self.state_map == 'W'] = \"##\"\n",
    "        state_arr[self.state_map == 'F'] = \"XX\"\n",
    "        state_arr[self.state_map == 'S'] = \"||\"\n",
    "        state_arr[self.state_map == 'U'] = \"??\"\n",
    "        state_arr[self.hospital] = \"Ho\"\n",
    "        state_arr[self.robot] = \"Ro\"\n",
    "        # Draw the people not at the hospital\n",
    "        for person, loc in self.people.items():\n",
    "            if loc == self.hospital:\n",
    "                continue\n",
    "            elif loc == self.robot:\n",
    "                person = \"R\" + person[-1]\n",
    "            state_arr[loc] = person\n",
    "        # Add padding\n",
    "        padded_state_arr = np.full((height + 2, width + 2), \"##\", dtype=object)\n",
    "        padded_state_arr[1:-1, 1:-1] = state_arr\n",
    "        state_arr = padded_state_arr\n",
    "        carrying_str = f\"Carrying: {self.carrying}\"\n",
    "        # Print\n",
    "        if msg:\n",
    "            print(msg)\n",
    "        for row in state_arr:\n",
    "            print(''.join(row))\n",
    "        print(carrying_str)\n",
    "        print()\n",
    "\n",
    "    def copy(self):\n",
    "        state_copy = copy.copy(self)\n",
    "        state_copy.state_map = self.state_map.copy()  # copy the numpy array\n",
    "        state_copy.people = self.people.copy()\n",
    "        return state_copy\n",
    "\n",
    "\n",
    "class SearchAndRescueProblem:\n",
    "    \"\"\"Defines a search and rescue (SAR) problem.\n",
    "\n",
    "    In search and rescue, a robot must navigate to, pick up, and\n",
    "    drop off people that are in need of help.\n",
    "\n",
    "    Actions are strs. The following actions are defined:\n",
    "      \"up\" / \"down\" / \"left\" / \"right\" : Moves the robot. The\n",
    "        robot cannot move into obstacles or off the map.\n",
    "      \"pickup-{person}\": If the robot is at the person, and if\n",
    "        the robot is not already carrying someone, picks them up.\n",
    "      \"dropoff\": If the robot is carrying a person, they are\n",
    "        dropped off at the robot's current location.\n",
    "      \"look...\": later we'll allow these actions, but they\n",
    "        have no effect on the state.\n",
    "\n",
    "    This structure serves as a container for a transition model\n",
    "    \"get_next_state(state, action)\", an observaton model \"get_observation(state)\"\n",
    "    and an action model \"get_legal_actions(state)\"\n",
    "\n",
    "    Example usage:\n",
    "      problem = SearchAndRescueProblem()\n",
    "      state = State()\n",
    "      state.render()\n",
    "      action = \"down\"\n",
    "      next_state = problem.get_next_state(state, action)\n",
    "      next_state.render()\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.action_deltas = {\n",
    "            \"up\": (-1, 0),\n",
    "            \"down\": (1, 0),\n",
    "            \"left\": (0, -1),\n",
    "            \"right\": (0, 1),\n",
    "        }\n",
    "\n",
    "    @staticmethod\n",
    "    def is_valid_location(loc_r, loc_c, state, verbose=False):\n",
    "        if not (0 <= loc_r < state.state_map.shape[0] and\n",
    "                0 <= loc_c < state.state_map.shape[1]):\n",
    "            if verbose:\n",
    "                print(\n",
    "                    \"WARNING: attempted to move out of bounds, action has no effect.\"\n",
    "                )\n",
    "            return False\n",
    "        if not state.get_safe_grid()[loc_r, loc_c]:\n",
    "            if verbose:\n",
    "                print(\n",
    "                    \"WARNING: attempted to move into an obstacle/unsafe region, action has no effect.\"\n",
    "                )\n",
    "            return False\n",
    "        return True\n",
    "\n",
    "    @staticmethod\n",
    "    def get_legal_actions(state):\n",
    "        legal_actions = [\"up\", \"down\", \"left\", \"right\", \"dropoff\"]\n",
    "        for person in state.people:\n",
    "            legal_actions.append(f\"pickup-{person}\")\n",
    "        return legal_actions\n",
    "\n",
    "    def get_next_state(self, state, action, verbose=False):\n",
    "        legal_actions = self.get_legal_actions(state)\n",
    "        if action not in legal_actions and not action.startswith('look'):\n",
    "            raise ValueError(\n",
    "                f\"Unrecognized action {action}. Actions must be one of: {legal_actions}\"\n",
    "            )\n",
    "\n",
    "        if action in [\"up\", \"down\", \"left\", \"right\"]:\n",
    "            dr, dc = self.action_deltas[action]\n",
    "            r, c = state.robot\n",
    "            if not self.is_valid_location(\n",
    "                    r + dr, c + dc, state, verbose=verbose):\n",
    "                if verbose:\n",
    "                    print(f\"Action {action} is invalid in {state}.\")\n",
    "                return state, False\n",
    "            new_state = state.copy()\n",
    "            new_state.robot = (r + dr, c + dc)\n",
    "            return new_state, True\n",
    "\n",
    "        elif action.startswith(\"pickup\"):\n",
    "            person = action.split(\"-\")[1]\n",
    "            if state.carrying is not None:\n",
    "                if verbose:\n",
    "                    print(\n",
    "                        \"WARNING: attempted to pick up a person while already carrying someone, action has no effect.\"\n",
    "                    )\n",
    "                return state, False\n",
    "            if person not in state.people or (state.people[person] !=\n",
    "                                              state.robot):\n",
    "                if verbose:\n",
    "                    print(\n",
    "                        \"WARNING: attempted to pick up a person not at the robot location, action has no effect.\"\n",
    "                    )\n",
    "                return state, False\n",
    "            new_state = state.copy()\n",
    "            del new_state.people[person]\n",
    "            new_state.carrying = person\n",
    "            return new_state, True\n",
    "\n",
    "        elif action == \"dropoff\":\n",
    "            if state.carrying is None:\n",
    "                if verbose:\n",
    "                    print(\n",
    "                        \"WARNING: attempted to dropoff while not carrying anyone, action has no effect.\"\n",
    "                    )\n",
    "                return state, False\n",
    "            person = state.carrying\n",
    "            new_state = state.copy()\n",
    "            new_state.carrying = None\n",
    "            new_state.people[person] = state.robot\n",
    "            return new_state, True\n",
    "\n",
    "        elif action.startswith('look'):\n",
    "            return state, True\n",
    "\n",
    "        else:\n",
    "            raise KeyError\n",
    "\n",
    "    def get_observation(self, state):\n",
    "        \"\"\"Return the states of the adjacent (non-wall) grid squares.\"\"\"\n",
    "        height, width = state.state_map.shape\n",
    "        deltas = self.action_deltas\n",
    "        r, c = state.robot\n",
    "        observation = {(r, c): state.state_map[r, c]}\n",
    "        for direction, (dr, dc) in deltas.items():\n",
    "            nr = r + dr\n",
    "            nc = c + dc\n",
    "            if not (0 <= nr < height and 0 <= nc < width):\n",
    "                continue\n",
    "            if state.state_map[nr, nc] == \"W\":\n",
    "                continue\n",
    "            observation[(nr, nc)] = state.state_map[nr, nc]\n",
    "        return observation\n",
    "\n",
    "\n",
    "def execute_plan(problem, plan, state):\n",
    "    for action in plan:\n",
    "        state.render(msg=f'execute_plan: {action}')\n",
    "        # Resulting state\n",
    "        state, valid = problem.get_next_state(state, action)\n",
    "        assert valid, ('Attempted to execute invalid action '+ state + ' ' + action)\n",
    "    state.render(msg=f'execute_plan: Final state')\n",
    "    return state\n",
    "\n",
    "\n",
    "def agent_loop(problem, initial_state, policy, initial_belief, max_steps=200):\n",
    "    \"\"\"See MP01 introduction.\"\"\"\n",
    "    state = initial_state\n",
    "    state.render(msg='initial state')\n",
    "    belief = initial_belief\n",
    "    belief.render(msg='initial belief')\n",
    "    # An initial observation\n",
    "    observation = problem.get_observation(state)\n",
    "    print('Initial observation', observation)\n",
    "    # Update the belief, first with transition, then with observation\n",
    "    belief = belief.update(problem, observation)\n",
    "    belief.render(msg='new belief')\n",
    "    for step in range(max_steps):\n",
    "        action = policy(belief)\n",
    "        if action in ('*Success*', '*Failure*'):\n",
    "            print('Terminate with', action)\n",
    "            return action, state, belief\n",
    "        # Resulting state\n",
    "        state, valid = problem.get_next_state(state, action)\n",
    "        assert valid, 'Attempted to execute invalid action'\n",
    "        # Get observation of grid squares around the robot\n",
    "        observation = problem.get_observation(state)\n",
    "        # Update the belief, first with transition, then with observation\n",
    "        belief = belief.update(problem, observation, action)\n",
    "        print('agent_loop: step', step, 'action', action, 'observation',\n",
    "              observation)\n",
    "        state.render(msg='new state')\n",
    "        belief.render(msg='new belief')\n",
    "    return '*Failure*', state, belief\n",
    "\n",
    "\n",
    "def get_num_delivered(state):\n",
    "    \"\"\"Returns the number of people located in the hospital.\"\"\"\n",
    "    num_delivered = 0\n",
    "    for loc in state.people.values():\n",
    "        if loc == state.hospital:\n",
    "            num_delivered += 1\n",
    "    return num_delivered\n",
    "\n",
    "\n",
    "def execute_count_num_delivered(problem, state, plan):\n",
    "    \"\"\"Execute a plan for search and rescue and count the number of people\n",
    "    delivered.\n",
    "\n",
    "    Args:\n",
    "      problem: A SearchAndRescueProblem\n",
    "      plan: A list of action strs, see SearchAndRescueProblem.\n",
    "\n",
    "    Returns:\n",
    "      num_delivered: int\n",
    "    \"\"\"\n",
    "    state = execute_plan(problem=problem, plan=plan, state=state)\n",
    "    return get_num_delivered(state)\n",
    "\n",
    "\n",
    "def run_planning(domain_pddl_str,\n",
    "                 problem_pddl_str,\n",
    "                 search_alg_name,\n",
    "                 heuristic=None):\n",
    "    \"\"\"Plan a sequence of actions to solve the given PDDL problem.\n",
    "\n",
    "    This function is a lightweight wrapper around pyperplan.\n",
    "\n",
    "    Args:\n",
    "      domain_pddl_str: A str, the contents of a domain.pddl file.\n",
    "      problem_pddl_str: A str, the contents of a problem.pddl file.\n",
    "      search_alg_name: A str, the name of a search algorithm in\n",
    "        pyperplan. Options: astar, wastar, gbf, bfs, ehs, ids, sat.\n",
    "      heuristic: A str or a pyperplan `Heuristic` class.\n",
    "        A str, the name of a heuristic in pyperplan.\n",
    "          Options: blind, hadd, hmax, hsa, hff, lmcut, landmark.\n",
    "        A pyperplan `Heuristic` class.\n",
    "          See: https://github.com/aibasel/pyperplan/blob/main/doc/documentation.md#implementing-new-heuristics\n",
    "\n",
    "    Returns:\n",
    "      plan: A list of actions; each action is a pyperplan Operator.\n",
    "    \"\"\"\n",
    "    # Parsing the PDDL\n",
    "    domain_file = tempfile.NamedTemporaryFile(delete=False, dir='.')\n",
    "    problem_file = tempfile.NamedTemporaryFile(delete=False, dir='.')\n",
    "    with open(domain_file.name, 'w') as f:\n",
    "        f.write(domain_pddl_str)\n",
    "    with open(problem_file.name, 'w') as f:\n",
    "        f.write(problem_pddl_str)\n",
    "    parser = Parser(domain_file.name, problem_file.name)\n",
    "    domain = parser.parse_domain()\n",
    "    problem = parser.parse_problem(domain)\n",
    "    os.remove(domain_file.name)\n",
    "    os.remove(problem_file.name)\n",
    "\n",
    "    # Ground the PDDL\n",
    "    task = grounding.ground(problem)\n",
    "\n",
    "    # Get the search alg\n",
    "    search_alg = planner.SEARCHES[search_alg_name]\n",
    "\n",
    "    if heuristic is None:\n",
    "        return search_alg(task)\n",
    "\n",
    "    if isinstance(heuristic, str):\n",
    "        # Get the heuristic from pyperplan\n",
    "        heuristic_initialized = planner.HEURISTICS[heuristic](task)\n",
    "    else:\n",
    "        # Use customized heuristic\n",
    "        heuristic_initialized = heuristic(task)\n",
    "\n",
    "    # Run planning\n",
    "    return search_alg(task, heuristic_initialized)\n",
    "\n",
    "\n",
    "# Test Cases\n",
    "\n",
    "# First problem\n",
    "P1_B0 = np.array([[\"U\", \"U\", \"U\", \"U\", \"U\"], [\"U\", \"U\", \"U\", \"U\", \"U\"],\n",
    "                  [\"U\", \"U\", \"U\", \"U\", \"U\"], [\"U\", \"U\", \"U\", \"U\", \"U\"],\n",
    "                  [\"U\", \"U\", \"U\", \"U\", \"U\"], [\"U\", \"U\", \"U\", \"U\", \"U\"]])\n",
    "\n",
    "P1_B1 = np.array([[\"C\", \"S\", \"C\", \"C\", \"C\"], [\"S\", \"U\", \"U\", \"U\", \"U\"],\n",
    "                  [\"S\", \"U\", \"U\", \"U\", \"U\"], [\"S\", \"U\", \"U\", \"U\", \"U\"],\n",
    "                  [\"C\", \"U\", \"U\", \"U\", \"U\"], [\"C\", \"C\", \"C\", \"C\", \"C\"]])\n",
    "\n",
    "P1_G0 = np.array([[\"C\", \"S\", \"C\", \"C\", \"C\"], [\"S\", \"F\", \"S\", \"C\", \"C\"],\n",
    "                  [\"S\", \"F\", \"S\", \"S\", \"S\"], [\"S\", \"F\", \"F\", \"F\", \"F\"],\n",
    "                  [\"C\", \"S\", \"S\", \"S\", \"S\"], [\"C\", \"C\", \"C\", \"C\", \"C\"]])\n",
    "\n",
    "# Second problem\n",
    "P2_B1 = np.array([[\"C\", \"S\", \"C\", \"C\", \"C\"], [\"S\", \"U\", \"U\", \"C\", \"U\"],\n",
    "                  [\"S\", \"U\", \"U\", \"C\", \"U\"], [\"S\", \"U\", \"U\", \"U\", \"U\"],\n",
    "                  [\"C\", \"U\", \"U\", \"C\", \"U\"], [\"C\", \"C\", \"C\", \"C\", \"C\"]])\n",
    "\n",
    "P2_G0 = np.array([[\"C\", \"S\", \"C\", \"C\", \"C\"], [\"S\", \"F\", \"S\", \"C\", \"C\"],\n",
    "                  [\"S\", \"F\", \"S\", \"C\", \"S\"], [\"S\", \"F\", \"F\", \"S\", \"F\"],\n",
    "                  [\"C\", \"S\", \"S\", \"C\", \"S\"], [\"C\", \"C\", \"C\", \"C\", \"C\"]])\n",
    "\n",
    "\n",
    "def test_policy(belief_map, true_map, problem, policy):\n",
    "    \"\"\"Test a policy on a SearchAndRescue problem.\n",
    "\n",
    "    Args:\n",
    "        belief_map: A numpy array specifying the belief map\n",
    "        true_map:   A numpy array specifying the state map\n",
    "        problem:    A SearchAndRescueProblem instance\n",
    "        policy:     A policy returned by a policy making fn.\n",
    "                    e.g. make_planner_policy(problem, planner)\n",
    "    \"\"\"\n",
    "    height, width = true_map.shape\n",
    "    bottom, right = height - 1, width - 1\n",
    "    robot = (0, right)\n",
    "    hospital = (bottom, right)\n",
    "    people = {'pp': (bottom, right - 1)}  # Peter Parker\n",
    "    carrying = None\n",
    "    # Environment state\n",
    "    env_state = State(robot=robot,\n",
    "                      hospital=hospital,\n",
    "                      people=people,\n",
    "                      carrying=carrying,\n",
    "                      state_map=true_map)\n",
    "    # Initial belief: omniscient\n",
    "    b0 = BeliefState(robot=robot,\n",
    "                     hospital=hospital,\n",
    "                     people=people,\n",
    "                     carrying=carrying,\n",
    "                     state_map=belief_map)\n",
    "    # Do it\n",
    "    return agent_loop(problem, env_state, policy, b0)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3437bb42-2f9f-4904-a2d3-02f64a4bd374",
   "metadata": {},
   "source": [
    "# 1. Planning in Search and Rescue \n",
    "\n",
    "Recall our \"search and rescue\" robot who is charged with navigating a sometimes dangerous grid to find and help people in need. A lot of the problems we will look at here will look familiar from the previous projects and some of the homeworks, but there are some key differences. Unlike in project 1, we will restrict ourselves to a deterministic problem domain; we will however look at both fully observed and partially observed cases.\n",
    "\n",
    "Let us first focus on a single planning problem in the search-and-rescuedomain, illustrated below:\n",
    "\n",
    "![search and rescue problem](sar_problem.png)\n",
    "\n",
    "This problem features four \"people\" (bears) with names p1, p2, p3, and p4. A robot, initialized in the top left corner, should navigate to each person, pick them up one by one, and deliver them to the hospital (bottom right).\n",
    "\n",
    "* We always know the locations of the people, the robot, and the hospital. \n",
    "* Some locations may have walls in them.  You know about all the walls in advance, as well.\n",
    "* There is also fire!  And smoke!  But, initially, you may not know which locations have fire and/or smoke.  Nonetheless, you need to move around in the domain, make observations, do belief updates, make \n",
    "plans, and rescue bears.\n",
    "* The way the environment works, whenever the robot enters a grid cell, it observes the true environment state of all the neighboring cells.  Each environment cell contains exactly one of:  wall ('W'), fire ('F'), smoke ('S') or nothing (clear, 'C').\n",
    "* The robot may safely enter any cell that is clear ('C') or contains smoke ('S').\n",
    "\n",
    "We will first consider planning to navigate to, pick up, and drop off people at a hospital, and we are going to ask you to put this all together into a planning and execution system!\n",
    "\n",
    "Take a Look at the code .  `State` is a class with the following attributes:\n",
    "\n",
    "* \"state_map\": a 2D numpy array of characters 'W', 'F', 'S', 'C'.\n",
    "* \"robot\": A (row, col) representing the robot's loc.\n",
    "* \"hospital\": A (row, col) representing the hospital's loc.\n",
    "* \"carrying\": The str name of a person being carried, or None, if no person is being carried.\n",
    "* \"people\": A dict mapping str people names to (row, col) locs. If a person is being carried, they do not appear in this dict.\n",
    "\n",
    "States have a couple of useful methods: `render` prints a representation of the state and `copy` does what you would expect. `get_safe_grid` returns a boolean numpy array where True represents a safe space (not fire or wall).\n",
    "\n",
    "Actions are strs. The following actions are defined:\n",
    "* \"up\" / \"down\" / \"left\" / \"right\" : Moves the robot. The robot cannot move into obstacles or off the map.\n",
    "* \"pickup-{person}\": If the robot is at the person, and if the robot is not already carrying someone, picks.\n",
    "* \"dropoff\": If the robot is carrying a person, they are dropped off at the robot's current location.  *Allow for there being multiple dropoff locations, even though we will only dropoff at hospitals in this example.*\n",
    "\n",
    "Please now take a moment to read the docstring for `SearchAndRescueProblem` to make sure that you understand the state and action spaces.\n",
    "\n",
    "Finally, we're going to use a Python PDDL planner called `pyperplan` [link](https://github.com/aibasel/pyperplan) to find our plans. \n",
    "\n",
    "Let's familiarize ourselve with State and SearchAndRescueProblem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef53809",
   "metadata": {
    "id": "8ef53809"
   },
   "source": [
    "### 1.1 Search and Rescue Warmup 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22714ba3-f8cd-4a02-9923-29f08db6af49",
   "metadata": {},
   "source": [
    "Let's make sure we can access fields of the SearchAndRescue State. Please write a function to check if a row and col have an obstacle in a SearchAndRescue State.\n",
    "\n",
    "For reference, our solution is **1** line(s) of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "045a6db7-d3bb-458b-9dd7-4070fce30f30",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def sar_warmup1(sar_state, row, col):\n",
    "    \"\"\"Check if a row and col have an obstacle in a SearchAndRescueProblem\n",
    "    state.\n",
    "\n",
    "    Args:\n",
    "      sar_state: A SearchAndRescue State.\n",
    "      row: An int.\n",
    "      col: An int.\n",
    "\n",
    "    Returns:\n",
    "      has_obstacle: True if (row, col) has an obstacle(wall) in sar_state.\n",
    "    \"\"\"\n",
    "    raise NotImplementedError() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65deb8e-13d8-434e-a8e3-9d25b12137ac",
   "metadata": {
    "id": "8ef53809"
   },
   "source": [
    "### 1.2 Search and Rescue Warmup 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1f6d6b",
   "metadata": {
    "id": "9f1f6d6b"
   },
   "source": [
    "Let's make sure we know how to encode a plan. Please write a function that returns a hand-coded list of actions that will deliver person 'p1' (in the image above) to the hospital location. (You'll need to work out the plan for yourself -- don't use `pyperplan` yet!)\n",
    "\n",
    "For reference, our solution is **1** line(s) of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5634908",
   "metadata": {
    "collapsed": true,
    "id": "c5634908",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def sar_warmup2():\n",
    "    \"\"\"Hand-code a list of actions that will deliver person 'p1' to the\n",
    "    hospital location.\n",
    "\n",
    "    Returns:\n",
    "      actions: A list of str actions that will take person p1 to the hospital loccation.\n",
    "    \"\"\"\n",
    "    raise NotImplementedError() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a4ec4f",
   "metadata": {
    "id": "56a4ec4f"
   },
   "source": [
    "### Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44779016",
   "metadata": {
    "collapsed": true,
    "id": "44779016",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def sar_warmup_test2():\n",
    "    problem = SearchAndRescueProblem()\n",
    "    plan = sar_warmup2()\n",
    "    state = execute_plan(problem, plan, State())\n",
    "    assert state.people[\"p1\"] == (6, 6)\n",
    "\n",
    "sar_warmup_test2()\n",
    "\n",
    "print('Tests passed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9925e4",
   "metadata": {
    "id": "1e9925e4"
   },
   "source": [
    "### 1.3 Search and Rescue PDDL Planner\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9e4738",
   "metadata": {
    "id": "2f9e4738"
   },
   "source": [
    "Now that you're warmed up, let's try making a planner to solve a SearchAndRescueProblem!\n",
    "\n",
    "The core function in this planner class is 'get_plan'. This function needs to do the following:\n",
    "1. Create PDDL domain and problem strings for search and rescue. The operators should work for any grid size, obstacles, people locations, and hospital location.\n",
    "2. Invoke `run_planning` using the given `search_algo` search algorithm with the `heuristic` heuristic.\n",
    "3. Convert the output of run_planning (pyperplan Operators) into actions that can be executed, via `execute_plan`.\n",
    "\n",
    "We have given you most of the structure of the needed functions, but you will need to look (carefully!) through the provided python to find the `TODO` sections that you need to complete. \n",
    "\n",
    "For reference, 'get_plan' takes ~1-2 seconds to run with our implementation if using 'gbf' search and 'hff' heuristic. To get credit on gradescope, make sure that your function finishes in <10 seconds.\n",
    "\n",
    "**Notes**:\n",
    "* In this problem, you will need to construct somewhat complicated strings.  We *strongly* encourage you to read about [Python-3 f-strings](https://www.digitalocean.com/community/tutorials/how-to-use-f-strings-to-create-strings-in-python-3) which make this process much easier than the alternatives.\n",
    "* You may find `state.render()` useful for debugging.\n",
    "* We also highly recommend printing out the domain and problem after they have been created, and copying them into [editor.planning.domains](http://editor.planning.domains) to check whether it's possible to find a plan. This editor can be helpful for syntax checking.\n",
    "* We also recommend writing careful test cases for yourself --- it's really easy to forget preconditions or effects. When Nick was debugging this, he forgot to make sure that the robot was at the location of the person, so the plans were (confusingly) super-short! \n",
    "* The image above with the robot and the bears is a faithful depiction of the initial state. For example, the initial locations of the people are: \"p1\": (4, 0), \"p2\": (6, 0), \"p3\": (0, 6), \"p4\": (3, 3).\n",
    "* One part of this problem that may be initially counterintuitive is the way that we'll represent locations in PDDL. In the problem, a location is a tuple of integers. PDDL does not support such representations -- everything needs to be just an object with a string name.\n",
    "So to represent a location like (3, 5), we will make a string \"l3-5\" (where the first character there is a lowercase L), and we'll create an object with that name, of type \"location\". We will also need a way to encode the fact that the robot can only move between adjacent locations in the grid.\n",
    "In Python, we can compare the numeric values of locations like (3, 5) and (3, 6) to see if they are neighbors. But in PDDL, all we have are the objects with string names, and we need to encode everything in terms of predicates. So, we will create a predicate `(conn ?v0 - location ?v1 - location ?v2 - direction)`, which says that location `?v0` is connected to location `?v1` in direction `?v2`. For example, `(conn l3-5 l3-6 right)` might appear in the initial state. We can then use these `conn` predicates in the preconditions of a `move` operator to encode the fact that the robot can only move between adjacent locations.\n",
    "* We do not recommend modelling the hospital explicitly with special objects / types / predicates. Instead, the goal should be to deliver all people to the hospital, that is, `l6-6`.\n",
    "In words, the goal should be \"person1 is at l6-6 and person2 is at l6-6 and person3 is at l6-6 and person4 is at l6-6.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1d72e0d",
   "metadata": {
    "id": "c1d72e0d"
   },
   "outputs": [],
   "source": [
    "class SearchAndRescuePlanner:\n",
    "    \"\"\"A planner for a search and rescue problem.\n",
    "\n",
    "    The core function in this class is 'get_plan'\n",
    "    This function does the following:\n",
    "        1. Create PDDL domain and problem strings for search and rescue. The operators should work for any grid size, obstacles, people locations, and hospital location.\n",
    "        2. Invoke `run_planning` using the given `search_algo` search algorithm with the `heuristic` heuristic.\n",
    "        3. Convert the output of run_planning (pyperplan Operators) into actions\n",
    "           that can be given to the SearchAndRescueProblem.\n",
    "\n",
    "    Example Usage:\n",
    "        problem = SearchAndRescueProblem()\n",
    "        state = State()\n",
    "\n",
    "        planner = SearchAndRescuePlanner(search_algo='astar', heuristic='lmcut')\n",
    "        plan, plan_time = planner.get_plan(state)\n",
    "        state = execute_plan(problem, plan, state)\n",
    "\n",
    "    'get_plan' Returns:\n",
    "        plan: A list of actions; each action is a str, see SearchAndRescueProblem.\n",
    "        plan_time: Total planning time(sec) used for plan searching.\n",
    "\n",
    "    For reference, 'get_plan' takes ~1-2 seconds to run with our implementation if using 'gbf' search and 'lmcut' heuristic.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, search_algo='astar', heuristic='lmcut'):\n",
    "        self.search_algo = search_algo\n",
    "        self.heuristic = heuristic\n",
    "\n",
    "    def generate_domain_pddl(self,\n",
    "                             domain_name,\n",
    "                             added_operators='',\n",
    "                             added_predicates=''):\n",
    "        # <<< TODO: fill in missing parts in the PDDL domain below >>>\n",
    "        predicates_str = \"\"\"(conn ?v0 - location ?v1 - location ?v2 - direction)\n",
    "        (is-clear ?v0 - location)\n",
    "        ; TODO: write more here\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        # <<< TODO: fill in missing parts in the PDDL domain below >>>\n",
    "        operators_str = \"\"\"(:action move-robot\n",
    "    :parameters (?from - location ?to - location ?dir - direction)\n",
    "    :precondition (and\n",
    "      (conn ?from ?to ?dir)\n",
    "      ; TODO: write more here\n",
    "      \n",
    "    )\n",
    "    :effect (and\n",
    "      ; TODO: write more here\n",
    "      \n",
    "    )\n",
    "  )\n",
    "  (:action pickup-person\n",
    "    :parameters (?person - person ?loc - location)\n",
    "    :precondition (and\n",
    "      ; TODO: write more here\n",
    "     \n",
    "    )\n",
    "    :effect (and\n",
    "      ; TODO: write more here\n",
    "     \n",
    "    )\n",
    "  )\n",
    "  (:action dropoff-person\n",
    "    :parameters (?person - person ?loc - location)\n",
    "    :precondition (and\n",
    "      ; TODO: write more here\n",
    "      \n",
    "    )\n",
    "    :effect (and\n",
    "      ; TODO: write more here\n",
    "      \n",
    "    )\n",
    "  )\"\"\"\n",
    "\n",
    "        domain_pddl = f\"\"\"(define (domain {domain_name})\n",
    "    (:requirements :typing)\n",
    "    (:types person location direction)\n",
    "    (:constants\n",
    "      down - direction\n",
    "      left - direction\n",
    "      right - direction\n",
    "      up - direction\n",
    "    )\n",
    "    (:predicates\n",
    "      {predicates_str}\n",
    "      {added_predicates}\n",
    "    )\n",
    "    {operators_str}\n",
    "    {added_operators}\n",
    ")\"\"\"\n",
    "        return domain_pddl\n",
    "\n",
    "    def get_plan(self, state):\n",
    "        search_algo, heuristic = self.search_algo, self.heuristic\n",
    "        domain_name, added_predicate, added_operator = self.update_pddl_domain()\n",
    "        domain_pddl = self.generate_domain_pddl(\n",
    "            domain_name,\n",
    "            added_operators=added_operator,\n",
    "            added_predicates=added_predicate)\n",
    "        # Create objects str\n",
    "        obj_str = self.get_obj_strs(state)\n",
    "\n",
    "        # Create init str\n",
    "        init_str = self.get_init_strs(state)\n",
    "\n",
    "        # Create goal str\n",
    "        goal_str = self.get_goal_strs(state)\n",
    "\n",
    "        problem_pddl = f\"\"\"(define (problem searchandrescue) (:domain {domain_name})\n",
    "      (:objects\n",
    "      {obj_str}\n",
    "      )\n",
    "      (:init\n",
    "      {init_str}\n",
    "      )\n",
    "      (:goal (and {goal_str}))\n",
    "    )\"\"\"\n",
    "\n",
    "        start_time = time.time()\n",
    "        plan = run_planning(domain_pddl, problem_pddl, search_algo, heuristic)\n",
    "        time_elapsed = time.time() - start_time\n",
    "        if plan is None:\n",
    "            print(\"Failed to find a plan.\")\n",
    "            return None, time_elapsed\n",
    "\n",
    "        # Convert operators to actions\n",
    "        actions = self.parse_plan(plan)\n",
    "        return actions, time_elapsed\n",
    "\n",
    "    def get_obj_strs(self, state):\n",
    "        height, width = state.state_map.shape\n",
    "        objects_strs = [f\"{person} - person\" for person in state.people]\n",
    "        # <<< TODO: add object strs for locations >>>\n",
    "       \n",
    "        \n",
    "        if state.carrying is not None:\n",
    "            objects_strs.append(f\"{state.carrying} - person\")\n",
    "        objects_str = \" \".join(objects_strs)\n",
    "        return objects_str\n",
    "\n",
    "    def get_init_strs(self, state):\n",
    "        height, width = state.state_map.shape\n",
    "        robot_r, robot_c = state.robot\n",
    "        init_strs = [f\"(robot-at l{robot_r}-{robot_c})\"]\n",
    "        for person, (r, c) in state.people.items():\n",
    "            init_strs.append(f\"(person-at {person} l{r}-{c})\")\n",
    "        if state.carrying is not None:\n",
    "            init_strs.append(f\"(carrying {state.carrying})\")\n",
    "        else:\n",
    "            init_strs.append(\"(handsfree)\")\n",
    "            \n",
    "        deltas = {\n",
    "            \"up\": (-1, 0),\n",
    "            \"down\": (1, 0),\n",
    "            \"left\": (0, -1),\n",
    "            \"right\": (0, 1),\n",
    "        }\n",
    "        \n",
    "        safe_grid = state.get_safe_grid()\n",
    "        for r in range(height):\n",
    "            for c in range(width):\n",
    "                # Here we're going to add one (conn ...) atom for every pair\n",
    "                # of adjacent locations.\n",
    "                for direction, (dr, dc) in deltas.items():\n",
    "                    if not (0 <= r + dr < height and 0 <= c + dc < width):\n",
    "                        continue\n",
    "                    # For example, if r == 0, c == 0, dr == 0, dc == 1, then\n",
    "                    # this line adds the atom (conn l0-0 l0-1 right).\n",
    "                    init_strs.append(\n",
    "                        f\"(conn l{r}-{c} l{r + dr}-{c + dc} {direction})\")\n",
    "                # <<< TODO: add more init strs >>>\n",
    "                \n",
    "\n",
    "        init_str = \" \".join(init_strs)\n",
    "        return init_str\n",
    "\n",
    "    def get_goal_strs(self, state):\n",
    "        goal_strs = []\n",
    "        hospital_r, hospital_c = state.hospital\n",
    "        # <<< TODO: add goal strs >>>\n",
    "\n",
    "        \n",
    "\n",
    "        if state.carrying is not None:\n",
    "            # <<< TODO: add goal strs >>>\n",
    "            \n",
    "            pass\n",
    "        goal_str = \" \".join(goal_strs)\n",
    "        return goal_str\n",
    "\n",
    "    def update_pddl_domain(self):\n",
    "        domain_name = 'searchandrescue'\n",
    "        added_predicate = ''\n",
    "        added_operator = ''\n",
    "        return domain_name, added_predicate, added_operator\n",
    "\n",
    "    def parse_plan(self, plan):\n",
    "        actions = []\n",
    "        for op in plan:\n",
    "            if \"move-robot\" in op.name:\n",
    "                _, direction = op.name[:-1].rsplit(\" \", 1)\n",
    "                action = direction\n",
    "            elif \"pickup-person\" in op.name:\n",
    "                _, person, _ = op.name.split(\" \")\n",
    "                action = f\"pickup-{person}\"\n",
    "            else:\n",
    "                assert \"dropoff-person\" in op.name\n",
    "                action = \"dropoff\"\n",
    "            actions.append(action)\n",
    "        return actions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13e38b9",
   "metadata": {
    "id": "f13e38b9"
   },
   "source": [
    "### Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29bb3232",
   "metadata": {
    "collapsed": true,
    "id": "29bb3232",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def sar_test():\n",
    "    problem = SearchAndRescueProblem()\n",
    "    planner = SearchAndRescuePlanner(search_algo=\"gbf\", heuristic=\"hff\")\n",
    "    state = State()\n",
    "    plan, plan_time = planner.get_plan(state)\n",
    "    assert execute_count_num_delivered(problem=problem, state=state,\n",
    "                                       plan=plan) == 4\n",
    "\n",
    "sar_test()\n",
    "\n",
    "print('Tests passed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f3b537",
   "metadata": {
    "id": "d8f3b537"
   },
   "source": [
    "# <a id=\"inference\">2. Inference from observations</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3ae309-085d-489f-892d-1c1ee99c5d18",
   "metadata": {},
   "source": [
    "Now, let's look at the inference problem.  This is similar to the problem we saw in homework 8. We will consider several problems with varying grid sizes and different sets of observations. For example, consider the grid below:\n",
    "```\n",
    "# Fire, Unknown, Clear, Smoke, Wall\n",
    "GRID0 = np.array([\n",
    "  [\"F\", \"U\", \"C\"],\n",
    "  [\"W\", \"C\", \"U\"],\n",
    "  [\"U\", \"U\", \"C\"]\n",
    "], dtype=object)\n",
    "```\n",
    "This grid has 9 locations and 5 observations: there is fire in the top left, wall below it, and the center, top right, and bottom right locations are all known to be clear of smoke or fire.\n",
    "\n",
    "We will assume the following axioms:\n",
    "1. Each location has exactly one of {smoke, fire, clear, wall}.\n",
    "\n",
    "2. There is smoke at a location only if there is a fire in at least one of the adjacent (above, below, left, right) locations. Diagonals are not adjacent!\n",
    "\n",
    "3. There is smoke _or_ fire at a location if there is a fire in at least one of the adjacent locations, unless it's known to be 'W'.\n",
    "\n",
    "Take a moment to run your human inference engine: which unknown values in the grid above can be determined?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea3d8da",
   "metadata": {
    "id": "1ea3d8da"
   },
   "source": [
    "### 2.1 Inferring unknown values \n",
    "\n",
    "Please write a program that takes a grid as input and infers unknown values.\n",
    "\n",
    "Your program should output a new grid with all determinable unknown values replaced with the inferred value. If an unknown value cannot be determined, it should be left unknown.\n",
    "\n",
    "**Your program should use sympy.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "932cbf09",
   "metadata": {
    "collapsed": true,
    "id": "932cbf09",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def infer_unknown_values(grid):\n",
    "    \"\"\"Fill in any unknown values in the grid that can be inferred.\n",
    "\n",
    "    Args: grid: A list of lists of \"F\", \"U\", \"S\", \"W\", or \"C\".\n",
    "    Returns:\n",
    "      inferred_grid: A copy of grid with some unknown values replaced.\n",
    "\n",
    "    Example:\n",
    "      >> grid = [\n",
    "      >>   [\"F\", \"U\", \"C\"],\n",
    "      >>   [\"W\", \"C\", \"U\"],\n",
    "      >>   [\"U\", \"U\", \"C\"]\n",
    "      >> ]\n",
    "      >> infer_unknown_values(grid)\n",
    "      >> [[\"F\" \"S\" \"C\"]\n",
    "      >>  [\"W\" \"C\" \"C\"]\n",
    "      >>  [\"U\" \"U\" \"C\"]]\n",
    "    \"\"\"\n",
    "    raise NotImplementedError() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25aa345",
   "metadata": {
    "id": "a25aa345"
   },
   "source": [
    "### Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471e7c2e",
   "metadata": {
    "collapsed": true,
    "id": "471e7c2e",
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "assert infer_unknown_values([[\"U\", \"F\"]]) == [[\"U\", \"F\"]]\n",
    "\n",
    "\n",
    "assert infer_unknown_values([[\"F\", \"U\", \"C\"], [\"S\", \"C\", \"U\"], [\"U\", \"U\", \"C\"]]) == [[\"F\", \"S\", \"C\"], [\"S\", \"C\", \"C\"], [\"U\", \"U\", \"C\"]]\n",
    "\n",
    "\n",
    "assert infer_unknown_values([[\"U\", \"C\", \"C\"], [\"S\", \"C\", \"U\"], [\"U\", \"U\", \"C\"]]) == [[\"C\", \"C\", \"C\"], [\"S\", \"C\", \"C\"], [\"F\", \"S\", \"C\"]]\n",
    "\n",
    "\n",
    "assert infer_unknown_values([[\"U\", \"S\", \"C\", \"U\"], [\"U\", \"U\", \"C\", \"U\"], [\"U\", \"S\", \"C\", \"U\"]]) == [[\"F\", \"S\", \"C\", \"C\"], [\"U\", \"U\", \"C\", \"C\"], [\"F\", \"S\", \"C\", \"C\"]]\n",
    "\n",
    "\n",
    "assert infer_unknown_values([[\"U\", \"U\", \"C\", \"U\", \"U\", \"U\", \"U\", \"U\"], [\"C\", \"U\", \"U\", \"U\", \"U\", \"U\", \"U\", \"U\"], [\"U\", \"U\", \"U\", \"U\", \"U\", \"U\", \"U\", \"U\"], [\"U\", \"U\", \"U\", \"U\", \"U\", \"U\", \"C\", \"C\"], [\"U\", \"U\", \"U\", \"U\", \"U\", \"U\", \"C\", \"C\"], [\"U\", \"C\", \"U\", \"U\", \"U\", \"U\", \"U\", \"U\"], [\"U\", \"U\", \"U\", \"F\", \"U\", \"U\", \"U\", \"U\"], [\"U\", \"U\", \"U\", \"U\", \"U\", \"U\", \"U\", \"U\"]]) == [[\"C\", \"C\", \"C\", \"U\", \"U\", \"U\", \"U\", \"U\"], [\"C\", \"U\", \"U\", \"U\", \"U\", \"U\", \"U\", \"U\"], [\"U\", \"U\", \"U\", \"U\", \"U\", \"U\", \"U\", \"U\"], [\"U\", \"U\", \"U\", \"U\", \"U\", \"U\", \"C\", \"C\"], [\"U\", \"U\", \"U\", \"U\", \"U\", \"U\", \"C\", \"C\"], [\"U\", \"C\", \"U\", \"U\", \"U\", \"U\", \"U\", \"U\"], [\"U\", \"U\", \"U\", \"F\", \"U\", \"U\", \"U\", \"U\"], [\"U\", \"U\", \"U\", \"U\", \"U\", \"U\", \"U\", \"U\"]]\n",
    "\n",
    "\n",
    "assert infer_unknown_values([[\"C\", \"U\", \"C\", \"U\", \"U\", \"C\", \"U\"], [\"U\", \"W\", \"W\", \"U\", \"C\", \"W\", \"W\"], [\"U\", \"F\", \"U\", \"U\", \"U\", \"F\", \"U\"], [\"C\", \"S\", \"W\", \"C\", \"U\", \"U\", \"U\"], [\"U\", \"U\", \"W\", \"U\", \"W\", \"U\", \"U\"], [\"C\", \"C\", \"U\", \"C\", \"U\", \"W\", \"U\"], [\"U\", \"W\", \"C\", \"U\", \"W\", \"U\", \"C\"]]) == [[\"C\", \"C\", \"C\", \"C\", \"C\", \"C\", \"C\"], [\"C\", \"W\", \"W\", \"C\", \"C\", \"W\", \"W\"], [\"S\", \"F\", \"U\", \"U\", \"S\", \"F\", \"U\"], [\"C\", \"S\", \"W\", \"C\", \"U\", \"U\", \"U\"], [\"C\", \"C\", \"W\", \"C\", \"W\", \"U\", \"U\"], [\"C\", \"C\", \"C\", \"C\", \"C\", \"W\", \"U\"], [\"C\", \"W\", \"C\", \"C\", \"W\", \"C\", \"C\"]]\n",
    "\n",
    "\n",
    "assert infer_unknown_values([[\"C\", \"U\", \"C\", \"U\", \"U\", \"C\", \"U\"], [\"U\", \"W\", \"W\", \"U\", \"C\", \"W\", \"W\"], [\"U\", \"F\", \"U\", \"U\", \"U\", \"F\", \"U\"], [\"C\", \"S\", \"W\", \"C\", \"U\", \"F\", \"U\"], [\"U\", \"U\", \"W\", \"U\", \"W\", \"U\", \"U\"], [\"C\", \"C\", \"U\", \"C\", \"U\", \"W\", \"F\"], [\"U\", \"W\", \"C\", \"U\", \"W\", \"U\", \"U\"]]) == [[\"C\", \"C\", \"C\", \"C\", \"C\", \"C\", \"C\"], [\"C\", \"W\", \"W\", \"C\", \"C\", \"W\", \"W\"], [\"S\", \"F\", \"U\", \"U\", \"S\", \"F\", \"U\"], [\"C\", \"S\", \"W\", \"C\", \"S\", \"F\", \"U\"], [\"C\", \"C\", \"W\", \"C\", \"W\", \"U\", \"U\"], [\"C\", \"C\", \"C\", \"C\", \"C\", \"W\", \"F\"], [\"C\", \"W\", \"C\", \"C\", \"W\", \"U\", \"U\"]]\n",
    "print('Tests passed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46909c4",
   "metadata": {
    "id": "b46909c4"
   },
   "source": [
    "### 2.2 Belief update"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c10831e4",
   "metadata": {
    "id": "c10831e4"
   },
   "source": [
    "Now let us use our ability to infer unknown values to finish the implementation of the update method for BeliefState.\n",
    "\n",
    "Make sure to look at the utilities defined at the top of this notebook, although you may not need to use all of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c807b37",
   "metadata": {
    "collapsed": true,
    "id": "1c807b37",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class BeliefState(State):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        if \"state_map\" not in kwargs:\n",
    "            self.state_map = np.array([['U', 'U', 'U', 'U', 'U', 'U', 'U'],\n",
    "                                       ['U', 'W', 'W', 'U', 'U', 'W', 'W'],\n",
    "                                       ['U', 'U', 'U', 'U', 'U', 'U', 'U'],\n",
    "                                       ['U', 'U', 'W', 'U', 'U', 'U', 'U'],\n",
    "                                       ['U', 'U', 'W', 'U', 'W', 'U', 'U'],\n",
    "                                       ['U', 'U', 'U', 'U', 'U', 'W', 'U'],\n",
    "                                       ['U', 'W', 'U', 'U', 'W', 'U', 'U']],\n",
    "                                      dtype=str)\n",
    "\n",
    "    def update(self, problem, obs, action=None):\n",
    "        \"\"\"\n",
    "        problem: SearchAndRescueProblem instance\n",
    "        obs: {loc: entry, loc: entry,...}\n",
    "        act: string or None\n",
    "\n",
    "        # <<< TODO: >>>\n",
    "            1. Do transition from action (if any)\n",
    "            2. Update from observation\n",
    "            3. Do inference\n",
    "        \"\"\"\n",
    "        raise NotImplementedError() \n",
    "\n",
    "    def get_optimistic_state(self):\n",
    "        \"\"\"Returns a copy of the belief with a completed map in which Unknowns\n",
    "        are assumed to be Clear.\"\"\"\n",
    "        new_state = self.copy()\n",
    "        new_state.state_map[self.state_map == 'U'] = 'C'\n",
    "        return new_state\n",
    "\n",
    "    def get_careful_state(self):\n",
    "        \"\"\"Returns a copy of the belief.\n",
    "\n",
    "        Unknown states will not be treated as safe, see get_safe_grid.\n",
    "        \"\"\"\n",
    "        return self.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cafd16ea",
   "metadata": {
    "id": "cafd16ea"
   },
   "source": [
    "### Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb50542c",
   "metadata": {
    "collapsed": true,
    "id": "fb50542c",
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def beliefupdate_test1():\n",
    "    state_map = np.array([[\"C\", \"S\", \"C\", \"C\", \"C\"], [\"S\", \"F\", \"S\", \"C\", \"C\"],\n",
    "                          [\"S\", \"F\", \"S\", \"S\", \"S\"], [\"S\", \"F\", \"F\", \"F\", \"F\"],\n",
    "                          [\"C\", \"S\", \"S\", \"S\", \"S\"], [\"C\", \"C\", \"C\", \"C\", \"C\"]])\n",
    "    beliefstate_map = np.array([[\"U\", \"U\", \"U\", \"U\", \"U\"],\n",
    "                                [\"U\", \"U\", \"U\", \"U\", \"U\"],\n",
    "                                [\"U\", \"U\", \"U\", \"U\", \"U\"],\n",
    "                                [\"U\", \"U\", \"U\", \"U\", \"U\"],\n",
    "                                [\"U\", \"U\", \"U\", \"U\", \"U\"],\n",
    "                                [\"U\", \"U\", \"U\", \"U\", \"U\"]])\n",
    "    problem = SearchAndRescueProblem()\n",
    "    state = State(state_map=state_map)\n",
    "    bel = BeliefState(state_map=beliefstate_map)\n",
    "    observation = problem.get_observation(state)\n",
    "    new_bel = bel.update(problem, observation)\n",
    "    assert new_bel.robot == (0, 0)\n",
    "    assert new_bel.state_map.tolist() == [['C', 'S', 'U', 'U', 'U'],\n",
    "                                          ['S', 'U', 'U', 'U', 'U'],\n",
    "                                          ['U', 'U', 'U', 'U', 'U'],\n",
    "                                          ['U', 'U', 'U', 'U', 'U'],\n",
    "                                          ['U', 'U', 'U', 'U', 'U'],\n",
    "                                          ['U', 'U', 'U', 'U', 'U']]\n",
    "\n",
    "beliefupdate_test1()\n",
    "\n",
    "\n",
    "def beliefupdate_test2():\n",
    "    state_map = np.array([[\"C\", \"S\", \"C\", \"C\", \"C\"], [\"S\", \"F\", \"S\", \"C\", \"C\"],\n",
    "                          [\"S\", \"F\", \"S\", \"S\", \"S\"], [\"S\", \"F\", \"F\", \"F\", \"F\"],\n",
    "                          [\"C\", \"S\", \"S\", \"S\", \"S\"], [\"C\", \"C\", \"C\", \"C\", \"C\"]])\n",
    "    beliefstate_map = np.array([[\"U\", \"U\", \"U\", \"U\", \"U\"],\n",
    "                                [\"S\", \"U\", \"U\", \"U\", \"U\"],\n",
    "                                [\"U\", \"U\", \"U\", \"U\", \"U\"],\n",
    "                                [\"U\", \"U\", \"U\", \"U\", \"U\"],\n",
    "                                [\"U\", \"U\", \"U\", \"U\", \"U\"],\n",
    "                                [\"U\", \"U\", \"U\", \"U\", \"U\"]])\n",
    "    problem = SearchAndRescueProblem()\n",
    "    state = State(state_map=state_map)\n",
    "    bel = BeliefState(state_map=beliefstate_map)\n",
    "\n",
    "    new_state, _ = problem.get_next_state(state, 'down')\n",
    "    observation = problem.get_observation(new_state)\n",
    "    new_bel = bel.update(problem, observation, 'down')\n",
    "    assert new_bel.robot == (1, 0)\n",
    "    assert new_bel.state_map.tolist() == [['C', 'S', 'U', 'U', 'U'],\n",
    "                                          ['S', 'F', 'U', 'U', 'U'],\n",
    "                                          ['S', 'U', 'U', 'U', 'U'],\n",
    "                                          ['U', 'U', 'U', 'U', 'U'],\n",
    "                                          ['U', 'U', 'U', 'U', 'U'],\n",
    "                                          ['U', 'U', 'U', 'U', 'U']]\n",
    "\n",
    "beliefupdate_test2()\n",
    "\n",
    "print('Tests passed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3795be7-3c70-4925-a96d-92b6d89c6d02",
   "metadata": {},
   "source": [
    "# <a id=\"integrated\">3. Putting It Together</a>\n",
    "\n",
    "It's time to bring the planning and the inference together! Look at the procedure `agent_loop` that takes as input:\n",
    "\n",
    "* \"initial_state\": (a true state of the environment, which includes a state map, as well as the current locations of the hospital, the robot and the people and whether the robot is carrying someone.\n",
    "* \"initial_belief\" (an initial belief state, which is like an environment state, except that the state map may include characters 'U' indicating that the contents of a location is unknown)\n",
    "* \"policy\" : a procedure that takes in a belief state and returns the next action to take;  the action can be one of the original actions or '*Success*' (which means the goal has been achieved and all the people are at the hospital) or '*Failure*' (which means that the agent is certain that the goal is impossible to achieve.)  \n",
    "* \"max_steps\" : just a total number of steps to run the simulation to avoid infinite loops\n",
    "\n",
    "We are going to ask you to write five different policies for this domain.\n",
    "\n",
    "1. Safe but not so smart\n",
    "1. Safe and smart\n",
    "1. Reckless\n",
    "1. Safe and smart if possible, else reckless\n",
    "1. Looks before it leaps\n",
    "\n",
    "### 3.1 Safe but not so smart\n",
    "\n",
    "The agent is scared and just running directly to the hospital. However, it at least takes observations into account as it moves.\n",
    "\n",
    "Let's make an agent that:\n",
    "\n",
    "* Updates the belief state based on every observation using propositional inference (implement the `belief.update` method that gets called in `agent_loop`).\n",
    "\n",
    "* Executes a policy that, given the currently updated belief, checks to see whether it can move safely into a square that is closer (in Manhattan distance) to the hospital.  If so, it returns the action that would move it closer.  If it reaches the hospital, it returns `*Success*`.  If it cannot safely make a move (due to walls or fire) closer to the hospital, it waves its arms in anguish and returns `*Failure*`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d9e721a1",
   "metadata": {
    "collapsed": true,
    "id": "d9e721a1",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def make_greedy_policy(problem):\n",
    "    def policy(belief):\n",
    "        \"\"\"Returns an action or '*Failure*\"\"\"\n",
    "        # TODO: complete\n",
    "       \n",
    "\n",
    "    # return the policy function\n",
    "    return policy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "450a7b58",
   "metadata": {
    "id": "450a7b58"
   },
   "source": [
    "### Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e009ee",
   "metadata": {
    "collapsed": true,
    "id": "37e009ee",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def policy_test1():\n",
    "    problem = SearchAndRescueProblem()\n",
    "    policy = make_greedy_policy(problem)\n",
    "\n",
    "    # Empty map\n",
    "    state = State()\n",
    "    state.state_map[:, :] = 'C'\n",
    "    bel = BeliefState()\n",
    "    bel.state_map[:, :] = 'C'\n",
    "\n",
    "    s_or_f, final_state, final_bel = agent_loop(problem, state, policy, bel)\n",
    "    print('Final robot location', final_state.robot)\n",
    "    assert s_or_f == '*Success*' and final_state.robot == final_state.hospital\n",
    "\n",
    "policy_test1()\n",
    "\n",
    "def policy_test2():\n",
    "    problem = SearchAndRescueProblem()\n",
    "\n",
    "    # Use default map\n",
    "    state = State()\n",
    "    bel = BeliefState()\n",
    "\n",
    "    policy = make_greedy_policy(problem)\n",
    "    s_or_f, final_state, final_bel = agent_loop(problem, state, policy, bel)\n",
    "    r, c = final_state.robot\n",
    "    hr, hc = final_state.hospital\n",
    "    distance = abs(hr - r) + abs(hc - c)\n",
    "    print('Final robot location', final_state.robot)\n",
    "    print('Final distance =', distance)\n",
    "    assert distance < 12\n",
    "\n",
    "policy_test2()\n",
    "\n",
    "print('Tests passed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed43cdb6",
   "metadata": {
    "id": "ed43cdb6"
   },
   "source": [
    "### 3.2 Safe and smart\n",
    "\n",
    "Let's try and make an agent that is both safe and a little smarter (although probably still a bit too conservative). \n",
    "\n",
    "We will continue to run the belief update method that you implemented above for the rest of these cases, so we only need to worry about the policy.  \n",
    "\n",
    "* The first time the policy is called to generate an action, it should formulate, in PDDL, a planning problem to find a complete plan for moving people to the hospital that only traverses squares that are known not to have fire or walls, and returns the first step.\n",
    "\n",
    "* On subsequent calls to the policy, it should just return the next step of the plan.\n",
    "\n",
    "Just as we did in Section 1, we want you to use `pyperplan`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7c249406",
   "metadata": {
    "id": "7c249406"
   },
   "outputs": [],
   "source": [
    "def make_planner_policy(problem, planner):\n",
    "    # Keep memory of plan and which step we're on\n",
    "    status = {'plan': None, 'step': None}\n",
    "\n",
    "    def policy(belief):\n",
    "        \"\"\"Returns an action string or '*Failure*' or '*Success*'.\"\"\"\n",
    "        raise NotImplementedError() \n",
    "    \n",
    "    # return the policy function\n",
    "    return policy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ae7e09",
   "metadata": {
    "id": "76ae7e09"
   },
   "source": [
    "### Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41779f8c",
   "metadata": {
    "id": "41779f8c"
   },
   "outputs": [],
   "source": [
    "def sar_policy_test():\n",
    "    problem = SearchAndRescueProblem()\n",
    "    base_planner = SearchAndRescuePlanner(search_algo=\"gbf\", heuristic=\"hff\")\n",
    "\n",
    "    def planner(state):\n",
    "        plan, time = base_planner.get_plan(state)\n",
    "        return plan\n",
    "\n",
    "    policy = make_planner_policy(problem, planner)\n",
    "    state = State()\n",
    "    # Observable\n",
    "    bel = BeliefState(state_map=state.state_map)\n",
    "    s_or_f, final_state, final_bel = agent_loop(problem, state, policy, bel)\n",
    "    assert get_num_delivered(final_state) == 4\n",
    "\n",
    "sar_policy_test()\n",
    "\n",
    "print('Tests passed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b48263c-86c3-46f3-a761-44e2f7622833",
   "metadata": {},
   "source": [
    "### 3.3 Reckless\n",
    "\n",
    "For this and the remaining questions, we're not going to autograde your solutions, and we're not providing test cases. We've given you boxes to hold your implementation, but you will need to define your own tests cases, and in section 4, we'll ask you to do some analysis.  \n",
    "\n",
    "First, let's try to make our agent more aggressive but still not step into the fire!   As we saw in 3.1, even if we make a plan that might cause us to move into the fire, just before we are about to take an action, we can know for sure whether there is fire in the square we are about to move into.   So, let's make an (almost) reckless replanning agent.\n",
    "\n",
    "* The first time the policy is called to generate an action, it should formulate in PDDL a planning problem to find a very optimistic  plan for moving people to the hospital that only traverses squares that are **not known to have** fire or walls, and returns the first step.\n",
    "\n",
    "* On subsequent calls to the policy, if the next step in the plan is safe to execute given the updated belief, it should return that action.  Otherwise, it should make a new plan!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "145a7adb-189a-4485-b04d-9fbd6c411818",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_reckless_policy(problem, planner):\n",
    "    # Keep memory of plan and which step we're on\n",
    "    status = {'plan': None, 'step': None}\n",
    "\n",
    "    def policy(belief):\n",
    "        \"\"\"Returns an action string or '*Failure*' or '*Success*'.\"\"\"\n",
    "        raise NotImplementedError() \n",
    "    \n",
    "    # return the policy function\n",
    "    return policy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "490b751d-cc22-4df0-944d-cabc29392412",
   "metadata": {},
   "source": [
    "Use the code below to run your policy and provide an execution trace. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38795870-e7c6-40b5-9f47-d1c9cc870fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "problem = SearchAndRescueProblem()\n",
    "base_planner = SearchAndRescuePlanner(search_algo=\"gbf\", heuristic=\"hff\")\n",
    "\n",
    "def reckless_planner(state):\n",
    "    plan, time = base_planner.get_plan(state)\n",
    "    return plan\n",
    "\n",
    "policy = make_reckless_policy(problem, reckless_planner)\n",
    "state = State()\n",
    "# Observable\n",
    "bel = BeliefState(state_map=state.state_map)\n",
    "s_or_f, final_state, final_bel = agent_loop(problem, state, policy, bel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3da4137-5473-44a2-8f62-f299d06ae75f",
   "metadata": {},
   "source": [
    "### 3.4 Safe and smart if possible, else reckless\n",
    "\n",
    "Try to construct a new policy that is a useful combination of \"safe and smart\" and \"reckless\" strategies, which combines the best aspects of each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f55fc3ef-f95b-49cc-b474-7968427e8337",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_hybrid_policy(problem, planner):\n",
    "    # Keep memory of plan and which step we're on\n",
    "    status = {'plan': None, 'step': None}\n",
    "\n",
    "    def policy(belief):\n",
    "        \"\"\"Returns an action string or '*Failure*' or '*Success*'.\"\"\"\n",
    "        raise NotImplementedError() \n",
    "    \n",
    "    # return the policy function\n",
    "    return policy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6739c01c-64f5-4165-b327-169145f4ee48",
   "metadata": {},
   "source": [
    "Use the code below to run your policy and provide an execution trace. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4b3b7d-0d02-454b-bf06-da77b7507fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "problem = SearchAndRescueProblem()\n",
    "base_planner = SearchAndRescuePlanner(search_algo=\"gbf\", heuristic=\"hff\")\n",
    "\n",
    "def hybrid_planner(state):\n",
    "    plan, time = base_planner.get_plan(state)\n",
    "    return plan\n",
    "\n",
    "policy = make_hybrid_policy(problem, hybrid_planner)\n",
    "state = State()\n",
    "# Observable\n",
    "bel = BeliefState(state_map=state.state_map)\n",
    "s_or_f, final_state, final_bel = agent_loop(problem, state, policy, bel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bdc1233-1d85-42e8-a532-dac3aa1bdfe9",
   "metadata": {},
   "source": [
    "### 3.5 Looks before it leaps\n",
    "\n",
    "Another way to approach this problem is to plan in belief space.  That sounds fancy, but actually can be relatively simple to do:\n",
    "\n",
    "* In your PDDL formulation, instead of just having a fluent `(is-clear ?loc)`, we'll have two fluents:  `(is-clear ?loc)` and `(is-unknown ?loc)`.\n",
    "\n",
    "* The precondition for moving into a square should still be `(is-clear ?loc)`.\n",
    "\n",
    "* You can add an operator that explicitly \"looks\" at a neighboring square;  we'll assume that it's optimistic and so if you look at a square that was previously unknown, it is now known to be clear.\n",
    "\n",
    "* Note that you can define a subclass of `SearchAndRescuePlanner` and redefine the `update_pddl_domain` method to add to the previous PDDL domain definition.  You'll also need to change the `parse_plan` method to handle the new action and the `get_init_strs` method to handle the new facts.\n",
    "\n",
    "* Make a replanning policy that plans in this belief-space formulation and executes its plan as long as it's safe, and replans otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0072c2ab-7a7d-4a48-a308-48b5d84cff7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_belief_space_policy(problem, planner):\n",
    "    # Keep memory of plan and which step we're on\n",
    "    status = {'plan': None, 'step': None}\n",
    "\n",
    "    def policy(belief):\n",
    "        \"\"\"Returns an action string or '*Failure*' or '*Success*'.\"\"\"\n",
    "        raise NotImplementedError() \n",
    "    \n",
    "    # return the policy function\n",
    "    return policy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "417f517b-c45a-4ecb-b9f1-fd6be7c8cddb",
   "metadata": {},
   "source": [
    "Use the code below to run your policy and provide an execution trace. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910d34a4-5eb4-47ea-9af0-4d9fdfc2c458",
   "metadata": {},
   "outputs": [],
   "source": [
    "problem = SearchAndRescueProblem()\n",
    "base_planner = SearchAndRescuePlanner(search_algo=\"gbf\", heuristic=\"hff\")\n",
    "\n",
    "def belief_planner(state):\n",
    "    plan, time = base_planner.get_plan(state)\n",
    "    return plan\n",
    "\n",
    "policy = make_belief_space_policy(problem, belief_planner)\n",
    "state = State()\n",
    "# Observable\n",
    "bel = BeliefState(state_map=state.state_map)\n",
    "s_or_f, final_state, final_bel = agent_loop(problem, state, policy, bel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19028585-5ce2-4b41-abf0-4f9905bcea65",
   "metadata": {},
   "source": [
    "# <a id=\"analysis\">4. Analysis</a>\n",
    "\n",
    "In the following questions, please provide textual answers in the provided boxes. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "383a1881-2ffa-48f9-bd14-7116f235efd1",
   "metadata": {},
   "source": [
    "* **First-order Logic:** In what way would having access to first-order logic have been helpful in this problem?\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "Write your answer in the cell below this one.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0baac1ad-544c-478f-b9dc-d460044e40f1",
   "metadata": {},
   "source": [
    "--> *(double click on this cell to delete this text and type your answer here)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c8d742-57a7-479a-b40d-7ed0a19d25d6",
   "metadata": {},
   "source": [
    "* **Heuristics:** The heuristics used in `pyperplan` are *domain-independent*; we can use them for Search and Rescue, for blocks world, etc.  An alternative strategy would be to hand-specify a *domain-specific* heuristic. What would a good domain-specific heuristics for search and rescue look like?\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "Write your answer in the cell below this one.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9858dd-f65e-447d-a0fd-ef826ca078b8",
   "metadata": {},
   "source": [
    "--> *(double click on this cell to delete this text and type your answer here)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559529cf-3b43-46f5-b118-29aea1d36d48",
   "metadata": {},
   "source": [
    "* **Look first:** We do one observation before choosing our first action.  Give an example scenario where omitting this step and using the reckless or two-phase planner would make an error.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "Write your answer in the cell below this one.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b71fad3-18aa-4ebf-b688-4298fae0ca25",
   "metadata": {},
   "source": [
    "--> *(double click on this cell to delete this text and type your answer here)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb7f52f-8db0-4907-9401-ac5d0d7ba684",
   "metadata": {},
   "source": [
    "* **Replanning:**  Currently, for the policies in 3.1-3.4, we replan whenever executing the next step would be unsafe. That might not be the best replanning strategy. Describe another strategy, give a concrete example of where it would do something differently than the current strategy,\n",
    "and say what the general trade-offs would be between that one and the current one."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7a1f86-ee7b-4777-9f91-795b88b7c725",
   "metadata": {},
   "source": [
    "--> *(double click on this cell to delete this text and type your answer here)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7516b84-4687-4b77-a493-82c4a2fff8ce",
   "metadata": {},
   "source": [
    "* **Planner Analysis:** Using the `test_policy` function, run your policies in the following three scenarios, specifically run:\n",
    "* The safe-and-smart planner\n",
    "* The reckless planner\n",
    "* The belief-space (looks before it leaps) planner\n",
    "with the scenarios defined as:\n",
    "* belief_map = P1_B0, true_map = P1_G0\n",
    "* belief_map = P1_B1, true_map = P1_G0\n",
    "* belief_map = P2_B1, true_map = P2_G0\n",
    "\n",
    "(These belief maps and true maps are all defined in the utility code at the top of this notebook.) \n",
    "\n",
    "In your answer below, don't count \"look\" as a step.\n",
    "* How many steps does each policy take to solve each problem?\n",
    "* Which method takes the fewest steps summed over all three problems?\n",
    "* Which one would you choose if planning is very expensive compared to execution?\n",
    "* Which one would you choose if execution is very expensive compared to planning? (In this case, what additional modifications might you make to your method)?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43f1f0d-6864-419c-b980-dc4b7ee92d76",
   "metadata": {},
   "source": [
    "--> *(double click on this cell to delete this text and type your answer here)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc79830-b216-4ff8-9b0a-2355abd933ce",
   "metadata": {},
   "source": [
    "# Submission \n",
    "\n",
    "Your final submission to gradescope should include this notebook, completed with your example runs and your completed text answers. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982949ec-8089-44eb-bd51-f71eae1b20e0",
   "metadata": {},
   "source": [
    "## Feedback\n",
    "\n",
    "If you have any feedback for us, please complete [this form](https://forms.gle/COMPLETE ME)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da1c411-6ad1-497d-9e33-7e757d54f8bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "mp01.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
